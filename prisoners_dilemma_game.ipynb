{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.test_model import TestModel\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from tools.prisoners_dilemma_tools import PrisonersDilemmaTools\n",
    "\n",
    "tools = [TavilySearchResults(max_results=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM-based personality\n",
    "personality_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an agent in a Prisoner's Dilemma game. Your personality is defined below:\"),\n",
    "    (\"system\", \"Personality: {personality}\"),\n",
    "    (\"user\", \"Craft a message to the other agent, based on your personality, to convince them whether you will cooperate or deceive.\")\n",
    "])\n",
    "\n",
    "def create_personality_agent(personality):\n",
    "    # Use the LLM to initialize agent personality and behavior\n",
    "    return {\n",
    "        \"personality\": personality,\n",
    "        \"intent\": \"\",\n",
    "        \"received_message\": \"\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def craft_message_with_llm(agent):\n",
    "    # Construct the message crafting prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    You are playing the Prisoner's Dilemma. \n",
    "    Your personality is as follows: {agent['personality']}\n",
    "    Do you want to cooperate or deceive? Compose a message to the other player that reflects your intent.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate the message via the LLM\n",
    "    response = llm.invoke({\"messages\": [prompt]})\n",
    "    agent['intent'] = response['content']\n",
    "    return response['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_router(agent1_message, agent2_message):\n",
    "    # Append messages to each other's states\n",
    "    agent1[\"received_message\"] = agent2_message\n",
    "    agent2[\"received_message\"] = agent1_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decision_with_llm(agent):\n",
    "    # Construct the decision prompt based on received message\n",
    "    decision_prompt = f\"\"\"\n",
    "    You are playing the Prisoner's Dilemma. \n",
    "    Your personality is as follows: {agent['personality']}\n",
    "    The other agent told you: {agent['received_message']}\n",
    "    You have said that you will: {agent['intent']}. \n",
    "    Do you decide to cooperate or betray? Respond with 'cooperate' or 'betray'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate the final decision via LLM\n",
    "    response = llm.invoke({\"messages\": [decision_prompt]})\n",
    "    return response['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GraphNode' from 'langgraph' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphNode, LangGraph\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Define nodes for the graph\u001b[39;00m\n\u001b[1;32m      4\u001b[0m message_node_agent1 \u001b[38;5;241m=\u001b[39m GraphNode(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent1 Message\u001b[39m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m=\u001b[39mcraft_message_with_llm, input_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'GraphNode' from 'langgraph' (unknown location)"
     ]
    }
   ],
   "source": [
    "from langgraph import GraphNode, LangGraph\n",
    "\n",
    "# Define nodes for the graph\n",
    "message_node_agent1 = GraphNode(name=\"Agent1 Message\", func=craft_message_with_llm, input_key=\"agent1\")\n",
    "message_node_agent2 = GraphNode(name=\"Agent2 Message\", func=craft_message_with_llm, input_key=\"agent2\")\n",
    "router_node = GraphNode(name=\"Message Router\", func=message_router)\n",
    "decision_node_agent1 = GraphNode(name=\"Agent1 Decision\", func=make_decision_with_llm, input_key=\"agent1\")\n",
    "decision_node_agent2 = GraphNode(name=\"Agent2 Decision\", func=make_decision_with_llm, input_key=\"agent2\")\n",
    "\n",
    "# Construct the graph\n",
    "graph = LangGraph(\n",
    "    nodes=[message_node_agent1, message_node_agent2, router_node, decision_node_agent1, decision_node_agent2],\n",
    "    edges=[\n",
    "        (\"Agent1 Message\", \"Message Router\"),\n",
    "        (\"Agent2 Message\", \"Message Router\"),\n",
    "        (\"Message Router\", \"Agent1 Decision\"),\n",
    "        (\"Message Router\", \"Agent2 Decision\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = TestModel()\n",
    "\n",
    "# Initialize agents\n",
    "agent1 = create_personality_agent(\"Rational and cautious. Values long-term trust.\")\n",
    "agent2 = create_personality_agent(\"Opportunistic, but cooperative when necessary.\")\n",
    "\n",
    "# Run the graph\n",
    "result = graph.run({\"agent1\": agent1, \"agent2\": agent2})\n",
    "\n",
    "# Output the decisions\n",
    "agent1_decision = result['agent1_decision']\n",
    "agent2_decision = result['agent2_decision']\n",
    "\n",
    "print(f\"Agent 1 decided to: {agent1_decision}\")\n",
    "print(f\"Agent 2 decided to: {agent2_decision}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
